{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>importing datasets</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "data = pd.read_csv('train.csv',nrows=600000,parse_dates=['pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copying data to train\n",
    "train = data.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping any missing values along the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of instances after removal of Nan Values is 599992\n"
     ]
    }
   ],
   "source": [
    "train= train.dropna(axis=0, how='any')\n",
    "print(\"The number of instances after removal of Nan Values is\",(data.shape[0]-train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key                  0\n",
       "fare_amount          0\n",
       "pickup_datetime      0\n",
       "pickup_longitude     0\n",
       "pickup_latitude      0\n",
       "dropoff_longitude    0\n",
       "dropoff_latitude     0\n",
       "passenger_count      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum() #Missing values are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(599992, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no. of instances having fare_amount greater than 150 is 66\n"
     ]
    }
   ],
   "source": [
    "print(\"The no. of instances having fare_amount greater than 150 is\",len(train[train.fare_amount>150]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing rows with fare_amount that is <b> less than zero or greater than 150 </b> along rows as it doesn't make any more sense in data based on domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [key, fare_amount, pickup_datetime, pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, passenger_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fare_outlier= train[(train['fare_amount']<0) | (train['fare_amount']>150)]\n",
    "train = train.drop(fare_outlier.index,axis=0)\n",
    "\n",
    "#checking for fare_amount that is less than zero and its being sucessfully removed from data\n",
    "train.loc[train['fare_amount']>150].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is inferred from the source https://www.flickr.com/places/info/2459115 that New York is bounded by the location cordinates <b>Latitude range is  from 40.568973 to 41.709555 and Longitude range is from -74.263242 to -72.986532 </b>so hence any cordinates not within these cordinates are not considered by us as we are only concerned with dropoffs which are within New York. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Removing latitude and longitude outliers  along rows</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train data  after removing latitude and longitude outliers (587203, 8)\n"
     ]
    }
   ],
   "source": [
    "train = train[((train.dropoff_longitude >= -74.263242) & (train.dropoff_longitude <= -72.986532) &\\\n",
    "                      (train.dropoff_latitude >= 40.568) & (train.dropoff_latitude <= 41.709)) & \\\n",
    "                       ((train.pickup_longitude >= -74.26) & (train.pickup_latitude >= 40.568)& \\\n",
    "                       (train.pickup_longitude <= -72.9865) & (train.pickup_latitude <= 41.7095))]\n",
    "\n",
    "print(\"The shape of train data  after removing latitude and longitude outliers\" , train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harvesian Formula to calculate distance given location coordinates\n",
    "haversine(θ) = sin²(θ/2)\n",
    "\n",
    "Eventually, the formual boils down to the following where φ is latitude, λ is longitude, R is earth’s radius (mean radius = 6,371km) to include latitude and longitude coordinates (A and B in this case).\n",
    "\n",
    "a = sin²((φB - φA)/2) + cos φA . cos φB . sin²((λB - λA)/2)\n",
    "\n",
    "c = 2 * atan2( √a, √(1−a) )\n",
    "\n",
    "d = R ⋅ c\n",
    "d = Haversine distance\n",
    "link:https://community.esri.com/groups/coordinate-reference-systems/blog/2017/10/05/haversine-formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1.030764\n",
       "1         8.450134\n",
       "2         1.389525\n",
       "3         2.799270\n",
       "4         1.999157\n",
       "            ...   \n",
       "599995    0.731451\n",
       "599996    1.923936\n",
       "599997    5.226628\n",
       "599998    3.396247\n",
       "599999    4.559847\n",
       "Length: 587203, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating new column H_Distance\n",
    "import numpy as np\n",
    "def haversine_distance(lat1, long1, lat2, long2):\n",
    "    data = [train]\n",
    "    for i in data:\n",
    "        R = 6371  #radius of earth in kilometers\n",
    "        #R = 3959 #radius of earth in miles\n",
    "        phi1 = np.radians(i[lat1])\n",
    "        phi2 = np.radians(i[lat2])\n",
    "    \n",
    "        delta_phi = np.radians(i[lat2]-i[lat1])\n",
    "        delta_lambda = np.radians(i[long2]-i[long1])\n",
    "    \n",
    "        #a = sin²((φB - φA)/2) + cos φA . cos φB . sin²((λB - λA)/2)\n",
    "        a = np.sin(delta_phi / 2.0) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2.0) ** 2\n",
    "    \n",
    "        #c = 2 * atan2( √a, √(1−a) )\n",
    "        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "        d = (R * c) #in kilometers\n",
    "        i['Distance_in_kms'] = d\n",
    "    return d\n",
    "haversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>Distance_in_kms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2009-06-15 17:26:21.0000001</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-06-15 17:26:21+00:00</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "      <td>1.030764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-05 16:52:16.0000002</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2010-01-05 16:52:16+00:00</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "      <td>8.450134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2011-08-18 00:35:00.00000049</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00+00:00</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "      <td>1.389525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2012-04-21 04:30:42.0000001</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2012-04-21 04:30:42+00:00</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "      <td>2.799270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2010-03-09 07:51:00.000000135</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2010-03-09 07:51:00+00:00</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "      <td>1.999157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             key  fare_amount           pickup_datetime  \\\n",
       "0    2009-06-15 17:26:21.0000001          4.5 2009-06-15 17:26:21+00:00   \n",
       "1    2010-01-05 16:52:16.0000002         16.9 2010-01-05 16:52:16+00:00   \n",
       "2   2011-08-18 00:35:00.00000049          5.7 2011-08-18 00:35:00+00:00   \n",
       "3    2012-04-21 04:30:42.0000001          7.7 2012-04-21 04:30:42+00:00   \n",
       "4  2010-03-09 07:51:00.000000135          5.3 2010-03-09 07:51:00+00:00   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.844311        40.721319         -73.841610         40.712278   \n",
       "1        -74.016048        40.711303         -73.979268         40.782004   \n",
       "2        -73.982738        40.761270         -73.991242         40.750562   \n",
       "3        -73.987130        40.733143         -73.991567         40.758092   \n",
       "4        -73.968095        40.768008         -73.956655         40.783762   \n",
       "\n",
       "   passenger_count  Distance_in_kms  \n",
       "0                1         1.030764  \n",
       "1                1         8.450134  \n",
       "2                2         1.389525  \n",
       "3                1         2.799270  \n",
       "4                1         1.999157  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creating new columns as year, month ,date , hour,  day of week </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['key', 'fare_amount', 'pickup_datetime', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count', 'Distance_in_kms', 'Year', 'Month', 'Date',\n",
       "       'Day of Week', 'Hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = [train]\n",
    "for i in all_data:\n",
    "    i['Year'] = i['pickup_datetime'].dt.year\n",
    "    i['Month'] = i['pickup_datetime'].dt.month\n",
    "    i['Date'] = i['pickup_datetime'].dt.day\n",
    "    i['Day of Week'] = i['pickup_datetime'].dt.dayofweek\n",
    "    i['Hour'] = i['pickup_datetime'].dt.hour\n",
    "\n",
    "train.columns #Manual checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dropping  where pickup latitude and pickup longitude are 0 but dropoff latitude and longitude are not 0, but the fare is 0\n",
    " and vice versa along rows</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train.loc[((train['pickup_latitude']==0) & (train['pickup_longitude']==0))&\\\n",
    "                             ((train['dropoff_latitude']!=0) & (train['dropoff_longitude']!=0)) \n",
    "                             & (train['fare_amount']==0)].index, axis=0)\n",
    "\n",
    "train=train.drop(train.loc[((train['pickup_latitude']!=0) & (train['pickup_longitude']!=0))&\\\n",
    "          ((train['dropoff_latitude']==0) & (train['dropoff_longitude']==0)) \n",
    "          & (train['fare_amount']==0)].index,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THe no. of rows with distance zero values is  6253\n"
     ]
    }
   ],
   "source": [
    "#counting number rows in distances_in_kms column with values zero\n",
    "print(\"THe no. of rows with distance zero values is \",len(train[train['Distance_in_kms']==0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Observation</b>\n",
    "\n",
    "We can see a few rows with distance =0. This could be due to 2 reasons\n",
    "\n",
    "The cab waited the whole time and the passenger eventually cancelled. That's why the pickup and drop co-ordinates are the same and maybe, the passenger was charged for the waiting time.\n",
    "The pickup and drop co-ordinates were not entered. In other words, these are missing values and need to ne imputed.\n",
    "\n",
    "With Google search i found formula to calculate missing values\n",
    "\n",
    "$$2.5 base-price + $1.56/km --> 6AM to 8PM Mon-Fri\n",
    "\n",
    "$$3.0 base-price + $1.56/km --> 8PM to 6AM Mon-Fri and Sat&Sun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping rows where fare_amount and Distance_in_kms are both zero along rows\n",
    "train = train.drop(train[(train['Distance_in_kms']==0)&(train['fare_amount']==0)].index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping rows Between 6AM and 8PM on Mon-Fri with Distance_in_kms is zero and fare is less than base price $2.5 along rows\n",
    "rush_hour = train.loc[(((train['Hour']>=6)&(train['Hour']<=20)) &\\\n",
    "                       ((train['Day of Week']>=1) & (train['Day of Week']<=5)) & \n",
    "                       (train['Distance_in_kms']==0) & \n",
    "                       (train['fare_amount'] < 2.5))]\n",
    "rush_hour\n",
    "train=train.drop(rush_hour.index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping rows Between 8PM and 6AM on Mon-Fri with Distance_in_kms is zero and fare is less than base price $3.0 along rows\n",
    "non_rush_hour = train.loc[(((train['Hour']<6)|(train['Hour']>20)) &\n",
    "                           ((train['Day of Week']>=1)&(train['Day of Week']<=5)) & \n",
    "                           (train['Distance_in_kms']==0) & \n",
    "                           (train['fare_amount'] < 3.0))]\n",
    "train=train.drop(non_rush_hour.index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping rows for Saturday and Sunday all hours with Distance_in_kms is zero and fare is less than base price $3.0 along rows\n",
    "weekends = train.loc[((train['Day of Week']==0) | (train['Day of Week']==6)) &\\\n",
    "                     (train['Distance_in_kms']==0) & \n",
    "                     (train['fare_amount'] < 3.0)]\n",
    "train=train.drop(weekends.index, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fare is 0, but Distance is not 0</b>. These values need to be imputed. we shall use the following formula\n",
    "\n",
    "fare = 2.5 + 1.56(Distance_in_kms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows with distance is non-zero but fare is zero is  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Creating data with distance not zero but fare is zero\n",
    "calculate_fare = train.loc[(train['Distance_in_kms']!=0) & (train['fare_amount']==0)]\n",
    "print(\"The number of rows with distance is non-zero but fare is zero is \",len(calculate_fare))\n",
    "\n",
    "#Calculation of fare_amount based on given distance using formula\n",
    "calculate_fare['fare_amount']=calculate_fare.apply(lambda x:((x.loc['Distance_in_kms']*1.56)+2.50),axis=1)\n",
    "\n",
    "#Updating modified rows in original train dataset\n",
    "train.update(calculate_fare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fare is not 0, but Distance is 0 </b>. These values need to be imputed using formula\n",
    "\n",
    "distance = (fare_amount - 2.5)/1.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows with distance is zero but fare is greater then base price $3 is  5712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Creating data with distance zero but fare is not zero\n",
    "calculate_distance= train.loc[(train['Distance_in_kms']==0) & (train['fare_amount']>3.0)]\n",
    "print(\"The number of rows with distance is zero but fare is greater then base price $3 is \",len(calculate_distance))\n",
    "\n",
    "#Calculating Distance based on given price using formula\n",
    "calculate_distance['Distance_in_kms'] = calculate_distance.apply(lambda row: ((row['fare_amount']-2.50)/1.56), axis=1)\n",
    "\n",
    "#Updating modified rows in original train dataset\n",
    "train.update(calculate_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no. of rows removed after preprocessing is  13013\n",
      "The original no.of rows and columns in actual dataset is  (600000, 8)\n",
      "the no.of rows and columns in after data preprocessing is  (586987, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"The no. of rows removed after preprocessing is \",(data.shape[0]-train.shape[0]))\n",
    "print(\"The original no.of rows and columns in actual dataset is \" ,data.shape)\n",
    "print(\"the no.of rows and columns in after data preprocessing is \" ,train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing key column and pickup_datatime as it doesn't make sense todata as key is referred as identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing features along the rows\n",
    "train = train.drop(['key','pickup_datetime'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fare_amount', 'pickup_longitude', 'pickup_latitude',\n",
       "       'dropoff_longitude', 'dropoff_latitude', 'passenger_count',\n",
       "       'Distance_in_kms', 'Year', 'Month', 'Date', 'Day of Week', 'Hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>Distance_in_kms</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>fare_amount</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.385264</td>\n",
       "      <td>-0.194624</td>\n",
       "      <td>0.301689</td>\n",
       "      <td>-0.165369</td>\n",
       "      <td>0.016453</td>\n",
       "      <td>0.837565</td>\n",
       "      <td>0.119014</td>\n",
       "      <td>0.026241</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>-0.019704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pickup_longitude</td>\n",
       "      <td>0.385264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125869</td>\n",
       "      <td>0.388257</td>\n",
       "      <td>0.132394</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.437031</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>-0.023192</td>\n",
       "      <td>0.017251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pickup_latitude</td>\n",
       "      <td>-0.194624</td>\n",
       "      <td>0.125869</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.149409</td>\n",
       "      <td>0.465461</td>\n",
       "      <td>-0.008012</td>\n",
       "      <td>-0.144887</td>\n",
       "      <td>-0.019741</td>\n",
       "      <td>-0.005528</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>-0.037123</td>\n",
       "      <td>0.028920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dropoff_longitude</td>\n",
       "      <td>0.301689</td>\n",
       "      <td>0.388257</td>\n",
       "      <td>0.149409</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.225522</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>0.349265</td>\n",
       "      <td>-0.000887</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.042557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dropoff_latitude</td>\n",
       "      <td>-0.165369</td>\n",
       "      <td>0.132394</td>\n",
       "      <td>0.465461</td>\n",
       "      <td>0.225522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004921</td>\n",
       "      <td>-0.124536</td>\n",
       "      <td>-0.011963</td>\n",
       "      <td>-0.004816</td>\n",
       "      <td>-0.001029</td>\n",
       "      <td>-0.028910</td>\n",
       "      <td>0.020097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>passenger_count</td>\n",
       "      <td>0.016453</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>-0.008012</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>-0.004921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010592</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>0.004385</td>\n",
       "      <td>0.037319</td>\n",
       "      <td>0.016179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Distance_in_kms</td>\n",
       "      <td>0.837565</td>\n",
       "      <td>0.437031</td>\n",
       "      <td>-0.144887</td>\n",
       "      <td>0.349265</td>\n",
       "      <td>-0.124536</td>\n",
       "      <td>0.010592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015896</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.015384</td>\n",
       "      <td>-0.030437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Year</td>\n",
       "      <td>0.119014</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>-0.019741</td>\n",
       "      <td>-0.000887</td>\n",
       "      <td>-0.011963</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.015896</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.117803</td>\n",
       "      <td>-0.009765</td>\n",
       "      <td>0.009265</td>\n",
       "      <td>0.002355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Month</td>\n",
       "      <td>0.026241</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>-0.005528</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>-0.004816</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>-0.117803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016281</td>\n",
       "      <td>-0.008687</td>\n",
       "      <td>-0.003581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Date</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>-0.001029</td>\n",
       "      <td>0.004385</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>-0.009765</td>\n",
       "      <td>-0.016281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.001888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Day of Week</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>-0.023192</td>\n",
       "      <td>-0.037123</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.028910</td>\n",
       "      <td>0.037319</td>\n",
       "      <td>0.015384</td>\n",
       "      <td>0.009265</td>\n",
       "      <td>-0.008687</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hour</td>\n",
       "      <td>-0.019704</td>\n",
       "      <td>0.017251</td>\n",
       "      <td>0.028920</td>\n",
       "      <td>-0.042557</td>\n",
       "      <td>0.020097</td>\n",
       "      <td>0.016179</td>\n",
       "      <td>-0.030437</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>-0.003581</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>-0.087672</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   fare_amount  pickup_longitude  pickup_latitude  \\\n",
       "fare_amount           1.000000          0.385264        -0.194624   \n",
       "pickup_longitude      0.385264          1.000000         0.125869   \n",
       "pickup_latitude      -0.194624          0.125869         1.000000   \n",
       "dropoff_longitude     0.301689          0.388257         0.149409   \n",
       "dropoff_latitude     -0.165369          0.132394         0.465461   \n",
       "passenger_count       0.016453          0.001164        -0.008012   \n",
       "Distance_in_kms       0.837565          0.437031        -0.144887   \n",
       "Year                  0.119014          0.002388        -0.019741   \n",
       "Month                 0.026241          0.005622        -0.005528   \n",
       "Date                  0.002025          0.000071        -0.001722   \n",
       "Day of Week           0.003856         -0.023192        -0.037123   \n",
       "Hour                 -0.019704          0.017251         0.028920   \n",
       "\n",
       "                   dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "fare_amount                 0.301689         -0.165369         0.016453   \n",
       "pickup_longitude            0.388257          0.132394         0.001164   \n",
       "pickup_latitude             0.149409          0.465461        -0.008012   \n",
       "dropoff_longitude           1.000000          0.225522        -0.001528   \n",
       "dropoff_latitude            0.225522          1.000000        -0.004921   \n",
       "passenger_count            -0.001528         -0.004921         1.000000   \n",
       "Distance_in_kms             0.349265         -0.124536         0.010592   \n",
       "Year                       -0.000887         -0.011963         0.006048   \n",
       "Month                       0.003900         -0.004816         0.005174   \n",
       "Date                        0.002425         -0.001029         0.004385   \n",
       "Day of Week                -0.000411         -0.028910         0.037319   \n",
       "Hour                       -0.042557          0.020097         0.016179   \n",
       "\n",
       "                   Distance_in_kms      Year     Month      Date  Day of Week  \\\n",
       "fare_amount               0.837565  0.119014  0.026241  0.002025     0.003856   \n",
       "pickup_longitude          0.437031  0.002388  0.005622  0.000071    -0.023192   \n",
       "pickup_latitude          -0.144887 -0.019741 -0.005528 -0.001722    -0.037123   \n",
       "dropoff_longitude         0.349265 -0.000887  0.003900  0.002425    -0.000411   \n",
       "dropoff_latitude         -0.124536 -0.011963 -0.004816 -0.001029    -0.028910   \n",
       "passenger_count           0.010592  0.006048  0.005174  0.004385     0.037319   \n",
       "Distance_in_kms           1.000000  0.015896  0.013555  0.002405     0.015384   \n",
       "Year                      0.015896  1.000000 -0.117803 -0.009765     0.009265   \n",
       "Month                     0.013555 -0.117803  1.000000 -0.016281    -0.008687   \n",
       "Date                      0.002405 -0.009765 -0.016281  1.000000     0.007365   \n",
       "Day of Week               0.015384  0.009265 -0.008687  0.007365     1.000000   \n",
       "Hour                     -0.030437  0.002355 -0.003581  0.001888    -0.087672   \n",
       "\n",
       "                       Hour  \n",
       "fare_amount       -0.019704  \n",
       "pickup_longitude   0.017251  \n",
       "pickup_latitude    0.028920  \n",
       "dropoff_longitude -0.042557  \n",
       "dropoff_latitude   0.020097  \n",
       "passenger_count    0.016179  \n",
       "Distance_in_kms   -0.030437  \n",
       "Year               0.002355  \n",
       "Month             -0.003581  \n",
       "Date               0.001888  \n",
       "Day of Week       -0.087672  \n",
       "Hour               1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As per my observation there is not redundant features so i took all the features to train the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creating train and test data and labels for training model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no. of rows and cols  train dataset is  (576987, 11)\n",
      "The no. of rows  and cols  test dataset is (10000, 11)\n",
      "The no. of labels in train dataset  (576987,)\n",
      "The no. of labels in train dataset  (10000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "train_data = train.iloc[ :len(train)-10000,:]\n",
    "\n",
    "train_label = train_data['fare_amount']\n",
    "train_data.drop('fare_amount',axis=1,inplace = True)\n",
    "\n",
    "test_data = train.iloc[len(train)-10000:,:]\n",
    "test_label = test_data['fare_amount']\n",
    "test_data.drop('fare_amount',axis=1,inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "print(\"The no. of rows and cols  train dataset is \", train_data.shape)\n",
    "print(\"The no. of rows  and cols  test dataset is\", test_data.shape)\n",
    "print(\"The no. of labels in train dataset \",train_label.shape)\n",
    "print(\"The no. of labels in train dataset \",test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
       "       'dropoff_latitude', 'passenger_count', 'Distance_in_kms', 'Year',\n",
       "       'Month', 'Date', 'Day of Week', 'Hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
       "       'dropoff_latitude', 'passenger_count', 'Distance_in_kms', 'Year',\n",
       "       'Month', 'Date', 'Day of Week', 'Hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BenchMark Model\n",
    "As the Gradient boosting was winner of this kaggle competition.The <b>benchmark Model that i selected was LightGBM.,</b>\n",
    "LightGBM is an open-source framework for gradient boosted machines. By default LightGBM will train a Gradient Boosted Decision Tree (GBDT), but it also supports random forests.\n",
    "\n",
    "The framework is fast and was designed for distributed training. It supports large-scale datasets and training on the GPU. In many cases LightGBM has been found to be more accurate and faster than XGBoost, though this is problem dependent.\n",
    "\n",
    "Link https://www.avanwyk.com/an-overview-of-lightgbm/\n",
    "\n",
    "\n",
    "Although we use other algorithms that are mentioned below\n",
    "\n",
    "Linear Regression\n",
    "\n",
    "DecisionTreeRegressor\n",
    "\n",
    "RandomForestRegressor\n",
    "\n",
    "XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>importing sklearn libraries </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Applying LightGBM</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root Mean square error for lightgbm is 3.951365261437285\n"
     ]
    }
   ],
   "source": [
    "#!pip install lightgbm\n",
    "import lightgbm as lgbm\n",
    "#Defing parameters\n",
    "\n",
    "param_lgbm={'boosting_type':'gbdt',\n",
    "    'learning_rate': 0.04,\n",
    " 'max_depth': 10,\n",
    " 'min_child_weight': 4,\n",
    " 'n_estimators': 100,\n",
    " 'n_jobs': -1,\n",
    " 'objective': 'regression',\n",
    " 'random_state': 42,\n",
    " 'reg_lambda': 0.003}\n",
    "\n",
    "\n",
    "train_set = lgbm.Dataset(train_data, train_label, silent=True)\n",
    "#training data\n",
    "model = lgbm.train(param_lgbm, train_set = train_set, num_boost_round=300)\n",
    "#predicting test data\n",
    "pred_lgbm = model.predict(test_data)\n",
    "lgbm_rmse = math.sqrt(mean_squared_error(test_label,pred_lgbm))\n",
    "print(\"The root Mean square error for lightgbm is\", lgbm_rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data.\n",
    "A linear regression line has an equation of the form Y = a + bX, where X is the explanatory variable and Y is the dependent variable. The slope of the line is b, and a is the intercept (the value of y when x = 0).\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Simple and easy to understand.\n",
    "\n",
    "Cheap computational cost.\n",
    "\n",
    "Ground for more complex machine learning algorithms.\n",
    "\n",
    "Disadvantages\n",
    "\n",
    "Prone to Outliers\n",
    "\n",
    "Poor performance if data is non-linear\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Applying Linear Regression</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error of Linear Regression is 5.485041813265747\n"
     ]
    }
   ],
   "source": [
    "#create regressor object\n",
    "linear_reg = LinearRegression(normalize = True)\n",
    "\n",
    "#fitting the train data\n",
    "linear_reg.fit(train_data,train_label)\n",
    "\n",
    "#Predicting test_data and printing the rmse score\n",
    "lin_reg_pred = linear_reg.predict(test_data)\n",
    "linear_rmse = math.sqrt(mean_squared_error(test_label,lin_reg_pred))\n",
    "print('The root mean square error of Linear Regression is', linear_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeRegressor\n",
    "Decision trees are predictive models that use a set of binary rules to calculate a target value. Each individual tree is a fairly simple model that has branches, nodes and leaves.\n",
    "\n",
    "Advantages\n",
    "\n",
    "It can be used for both Classification and Regression problems\n",
    "Easy to Understand, Interpret, Visualise\n",
    "\n",
    "Disadvantages; \n",
    "Over fitting: Over fitting is one of the most practical difficulty for decision tree models. This problem gets solved by setting constraints on model parameters and pruning (discussed in detailed below).\n",
    "\n",
    "Not fit for continuous variables: While working with continuous numerical variables, decision tree looses information when it categorizes variables in different categories.\n",
    "Cannot extrapolate.\n",
    "\n",
    "Link to detaled explanation: https://gdcoder.com/decision-tree-regressor-explained-in-depth/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Applying DecisionTreeRegressor </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse error of Decision tree regressor is  4.313312548010092\n"
     ]
    }
   ],
   "source": [
    "# create a regressor object \n",
    "regressor = DecisionTreeRegressor(min_samples_leaf = 6, min_samples_split = 2,splitter = 'best', random_state = 0)  \n",
    "  \n",
    "# fit the regressor with X and Y data \n",
    "regressor.fit(train_data, train_label) \n",
    "\n",
    "#predicting test_data and showing rmse score\n",
    "y_pred_dec_tree = regressor.predict(test_data)\n",
    "decisiontree_rmse = math.sqrt(mean_squared_error(test_label , y_pred_dec_tree))\n",
    "print('The rmse error of Decision tree regressor is ',decisiontree_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest Regressor\n",
    "\n",
    "Random Forest is an ensemble machine learning technique capable of performing both regression and classification tasks using multiple decision trees and a statistical technique called bagging.Random forest builds multiple decision trees and merge their predictions together to get a more accurate and stable prediction rather than relying on individual decision trees.\n",
    "\n",
    "Advantages\n",
    "\n",
    "Reduction in overfitting: by averaging several trees, there is a significantly lower risk of overfitting.\n",
    "\n",
    "It is very easy to measure the relative importance of each feature on the prediction\n",
    "\n",
    "Link https://gdcoder.com/random-forest-regressor-explained-in-depth/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Applying RandomForestRegressor on train data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   52.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error for Random Forest Regressor is  3.8761570926860993\n",
      "Wall time: 55.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Create predictor regressor\n",
    "rf = RandomForestRegressor(n_estimators = 20, max_depth = 16, max_features = None, oob_score = True, \n",
    "                                      bootstrap = True, verbose = 1, n_jobs = -1,random_state=40)\n",
    "\n",
    "#training data\n",
    "rf.fit(train_data, train_label)\n",
    "\n",
    "#predicting result and printing rmse score\n",
    "rf_predict = rf.predict(test_data)\n",
    "\n",
    "rf_rmse = math.sqrt(mean_squared_error(test_label,rf_predict))\n",
    "\n",
    "print(\"The root mean square error for Random Forest Regressor is \", rf_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "XGBoost is an implementation of Gradient Boosting Machines (GBM) and is used for supervised learning.\n",
    "\n",
    "The features that standout are Speed, Awareness of sparse data, distributed systems and out-of-core-computation and Parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Applying XGBoost model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error of xgBoost is 4.089037110077677\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_data, label=train_label)\n",
    "dtest = xgb.DMatrix(test_data)\n",
    "#set parameters for xgboost\n",
    "params = {'max_depth':6,\n",
    "          'eta':1,\n",
    "          'silent':1,\n",
    "          'objective':'reg:linear',\n",
    "          'eval_metric':'rmse',\n",
    "          'learning_rate':0.05\n",
    "         }\n",
    "\n",
    "num_rounds = 50\n",
    "#training data\n",
    "xb = xgb.train(params, dtrain, num_rounds)\n",
    "#predicting test result\n",
    "y_pred_xgb = xb.predict(dtest)\n",
    "xgb_rmse = math.sqrt(mean_squared_error(test_label,y_pred_xgb))\n",
    "print('The root mean square error of xgBoost is',xgb_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithms</th>\n",
       "      <th>RMSE error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>XgBoost</td>\n",
       "      <td>4.089037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Linear_regression</td>\n",
       "      <td>5.485042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Decision_tree_reg</td>\n",
       "      <td>4.313313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Random_forest_reg</td>\n",
       "      <td>3.876157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(BenchMark Model)Lightgbm</td>\n",
       "      <td>3.951365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Algorithms  RMSE error\n",
       "0                    XgBoost    4.089037\n",
       "1          Linear_regression    5.485042\n",
       "2          Decision_tree_reg    4.313313\n",
       "3          Random_forest_reg    3.876157\n",
       "4  (BenchMark Model)Lightgbm    3.951365"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_score = pd.DataFrame({ \"Algorithms\" :['XgBoost','Linear_regression','Decision_tree_reg',\n",
    "                                                  'Random_forest_reg','(BenchMark Model)Lightgbm'],\n",
    "                                     \"RMSE error\": [xgb_rmse,linear_rmse,decisiontree_rmse,rf_rmse,lgbm_rmse]\n",
    "                                 })\n",
    "all_model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: Based on rmse score of all model ,RandomForest outperforms BenchMark Model.But Still i decided to choose Benchmark Model(LightGBM) for tunning it with gridsearchCv to get best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Refinement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>HyperParameter Tunning for BenchMark Model(LightGBM) Using GridSearchCV</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
       "                                     colsample_bytree=1.0,\n",
       "                                     importance_type='split', learning_rate=0.1,\n",
       "                                     max_depth=-1, min_child_samples=20,\n",
       "                                     min_child_weight=0.001, min_split_gain=0.0,\n",
       "                                     n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "                                     objective=None, random_state=None,\n",
       "                                     reg_alpha=0.0, reg_lambda...\n",
       "                                     subsample_freq=0),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.03, 0.05],\n",
       "                         'max_depth': [5, 10, -1],\n",
       "                         'min_child_weight': [1, 3, 5], 'min_split_gain': [0.5],\n",
       "                         'n_estimators': [50, 100], 'n_jobs': [-1],\n",
       "                         'objective': ['regression'], 'random_state': [42],\n",
       "                         'reg_lambda': [0.001, 0.002, 0.003]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "params1 = {\n",
    "    'max_depth': [5,10,-1],\n",
    "    'learning_rate': [0.01, 0.03, 0.05],\n",
    "    'min_child_weight': [1,3,5],\n",
    "    'reg_lambda': [0.001, 0.002, 0.003],\n",
    "    'n_estimators':[50,100],\n",
    "    # fixed params\n",
    "    'n_jobs': [-1],\n",
    "    'objective': ['regression'],\n",
    "    'random_state': [42],\n",
    "    'min_split_gain':[0.5]\n",
    "}\n",
    "clf = lgbm.LGBMRegressor(scoring='rmse')\n",
    "lgb = GridSearchCV(clf, params1, cv=5, n_jobs=-1)\n",
    "\n",
    "lgb.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05,\n",
       " 'max_depth': -1,\n",
       " 'min_child_weight': 1,\n",
       " 'min_split_gain': 0.5,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'objective': 'regression',\n",
       " 'random_state': 42,\n",
       " 'reg_lambda': 0.001}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the best Parameters of LightGBM\n",
    "lgb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Lightgbm Final model Evaluation with tunned parameters</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error after using tunned parameters is 3.8007249025774894\n"
     ]
    }
   ],
   "source": [
    "#defining parameters\n",
    "params1 = {\n",
    "    'boosting_type':'gbdt',\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.05,\n",
    "    'min_child_weight': 1,\n",
    "    'reg_lambda': 0.001,\n",
    "    'n_jobs': [-1],\n",
    "    'objective': ['regression'],\n",
    "    'random_state': [42],\n",
    "    'min_split_gain': 0.5,\n",
    "    'min_child_samples': 10\n",
    "}\n",
    "\n",
    "\n",
    "train_set = lgbm.Dataset(train_data, train_label, silent=True)\n",
    "#training data\n",
    "model = lgbm.train(params1, train_set = train_set, num_boost_round=300)\n",
    "#Predicting result\n",
    "tunedlgbm_predict = model.predict(test_data)\n",
    "tunedlgbm = math.sqrt(mean_squared_error(test_label,tunedlgbm_predict))\n",
    "print(\"The root mean square error after using tunned parameters is\",tunedlgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM performs better among the other models.\n",
    "\n",
    "The Tuned LightGBM RMSE score(3.800724) was quite less than other models after tunning its hyperparameters\n",
    "\n",
    "No. of features used in model is 11\n",
    "\n",
    "We can Further refine models to get good score \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
